{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e1a4ff05",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1a4ff05",
        "outputId": "e9fad1d4-d68d-4a01-f589-cfa13f1b0450"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install transformers -U -q\n",
        "import torch\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "462b103f",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "462b103f",
        "outputId": "a30970ac-0d1c-458a-ddd7-2dc1a992dc21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.3 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.8/1.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n"
          ]
        }
      ],
      "source": [
        "! pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "49b92691",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49b92691",
        "outputId": "241ac521-00fa-491b-b7c8-cca7a5a472a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformers==4.35.0\n"
          ]
        }
      ],
      "source": [
        "!pip freeze | grep transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "4a80f4de",
      "metadata": {
        "id": "4a80f4de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42643eda-9210-4145-ff4d-40b66570c3cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "comment खण्ड में अपनी प्रतिक्रिया को निश्‍चित ही share करें ।\n",
            "तो यह एक बड़ा video है, तो भी मैं स्पष्ट रूप से सभी उत्पादों का mention करेंगे।\n",
            "मैं अपने बैग के लिए इंतजार कर रहा था.\n"
          ]
        }
      ],
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "\n",
        "# Load the MarianMT model and tokenizer\n",
        "model_name = 'Helsinki-NLP/opus-mt-en-hi'\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "model = MarianMTModel.from_pretrained(model_name)\n",
        "\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "def is_noun(text):\n",
        "    ans = nltk.pos_tag([text])\n",
        "    val = ans[0][1]\n",
        "\n",
        "    if val in ('NN', 'NNS', 'NNPS', 'NNP'):\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "# Input sentences\n",
        "input_text = [\"Definitely share your feedback in the comment section.\",\n",
        "              \"So even if it's a big video, I will clearly mention all the products.\",\n",
        "              \"I was waiting for my bag.\"]\n",
        "\n",
        "# Function to translate and preserve nouns\n",
        "def translate_and_preserve_nouns(input_text):\n",
        "    translated_sentences = []\n",
        "\n",
        "    for text in input_text:\n",
        "        # Convert sentences to tensors\n",
        "        model_inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "        # Translate from English to Hindi\n",
        "        generated_tokens = model.generate(**model_inputs)\n",
        "\n",
        "        translation = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n",
        "\n",
        "        # Split the input text into words\n",
        "        words = text.split()\n",
        "\n",
        "        # Initialize a list to store nouns\n",
        "        noun_list = [word for word in words if is_noun(word)]\n",
        "\n",
        "        # Translate English nouns to Hindi and replace them in the translated sentence\n",
        "        for noun in noun_list:\n",
        "            noun = noun.replace(',', '')\n",
        "            model_inputs_noun = tokenizer(noun, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "            generated_tokens_noun = model.generate(**model_inputs_noun)\n",
        "\n",
        "            noun_translation = tokenizer.decode(generated_tokens_noun[0], skip_special_tokens=True)\n",
        "\n",
        "            # Replace the noun_translation (a list) with the original noun (a string)\n",
        "            translation = translation.replace(noun_translation, noun)\n",
        "\n",
        "        translated_sentences.append(translation)\n",
        "\n",
        "    return translated_sentences\n",
        "\n",
        "# Call the function and print the translated sentences\n",
        "translated_sentences = translate_and_preserve_nouns(input_text)\n",
        "for sentence in translated_sentences:\n",
        "    print(sentence)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate translated sentences qualitatively\n",
        "def evaluate_qualitatively(translated_sentences, input_text):\n",
        "    print(\"Original English Text:\")\n",
        "    for text in input_text:\n",
        "        print(text)\n",
        "\n",
        "    print(\"\\nTranslated Hinglish Text:\")\n",
        "    for sentence in translated_sentences:\n",
        "        print(sentence)\n",
        "\n",
        "# Call the function to evaluate the translations qualitatively\n",
        "evaluate_qualitatively(translated_sentences, input_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsa0nc8mcgJ-",
        "outputId": "f2f7a165-c09f-4912-ea4c-602d4f94538d"
      },
      "id": "tsa0nc8mcgJ-",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original English Text:\n",
            "Definitely share your feedback in the comment section.\n",
            "So even if it's a big video, I will clearly mention all the products.\n",
            "I was waiting for my bag.\n",
            "\n",
            "Translated Hinglish Text:\n",
            "comment खण्ड में अपनी प्रतिक्रिया को निश्‍चित ही share करें ।\n",
            "तो यह एक बड़ा video है, तो भी मैं स्पष्ट रूप से सभी उत्पादों का mention करेंगे।\n",
            "मैं अपने बैग के लिए इंतजार कर रहा था.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yMNc1ut7lMlh"
      },
      "id": "yMNc1ut7lMlh",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}